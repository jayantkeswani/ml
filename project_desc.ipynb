{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is for the class of OPS802. The target of the project is to have a hands on full data analytics experience from A to Z. That means starting with raw data and reading it into python then doing some analytical and statstical observations on the data and finally doing some supervised and unsupervised learning on the data. The data we will use for this project is one of the most famous datasets in the machine learning world which is called IRIS classification dataset. That means there is plenty of resources for you online to learn from and that you are not the first person who saw and analyzed this data. Use this to your advantage. The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\" as an example of linear discriminant analysis. We will describe it more in details later. The project measures the capabilities of lodaing data, cleaning it up, running some tests and statistical analysis and finally machine learning. The following highlights the project\n",
    "-  The project consists of four parts, they are mostly independent and in order based on what we studies in class\n",
    "-  The deadline of the project is the last day of the quarter\n",
    "-  The project is individual, however I encourage you to talk to each other to check your different approaches without copying codes or talking about detailed code specific. For example, it is ok to ask about which function you have used to tackle part a and is it better than this other function or not. It is not ok to copy the exact code including that function you asked about.\n",
    "- You are expected to heavily utilize resources outside the class notebooks such as Google, StackOverflow, .. etc\n",
    "- Code cleanings and Display has 10% of the grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1: Data Loading and Cleaning up\n",
    "The iris flower dataset consists of 150 collected observations for different flower's charachteristics. The dataset contains four attributes. These four attributes help decide which Iris class does the flower belong to. The four attributes are sepal length, sepal width, petal length, and petal width; all in cm. The data set contains 3 classes Iris Setosa, Iris Versicolour, and Iris Virginica. For more info about the dataset, you can chek [this link](https://en.wikipedia.org/wiki/Iris_flower_data_set). The end target of the project will be to build a model that can predict, based on the four attributes, which class does the flower belong to.\n",
    "\n",
    "In the first part of the project we will start by loading the data and cleaning up any problems within the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load the Iris dataset using the file iris.data. You can open it with any text editor to find out how it looks like. Decide which separator you would like to use and if any rows needs to be skipped\n",
    "<br>\n",
    "Now let's do some exploring\n",
    "- How many rows and colums are in the file\n",
    "- How many nulls in the file\n",
    "- Which rows contains nans and how many nans in each of these rows\n",
    "- How many nans per columns?\n",
    "- The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" based on the original paper. Is that what you have? If not, fix it\n",
    "- The 39th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\",  where the errors are in the second and third features. Fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Stastical Exploring\n",
    "In this part we will understand a little more about the data and do some cool plottings\n",
    "- What is the mean and variance for each column and use the function describe to get insights about the data\n",
    "- Drop the nan rows\n",
    "- Recaluclate the mean and variance for each column\n",
    "- What is the correlation between the fourth column and each of the other three columns individually? Any observations\n",
    "- How many records exist for each class. # Hint, you can do this in one line by using groupby\n",
    "- Change the random seed to 1234 and randomly pick 20 samples of the data and display it\n",
    "- Plot histogram for all the data attributes\n",
    "- Plot histogram for all the data attributes per feature, i.e. grouped by features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Statistical Analysis \n",
    "In this part, you will explore some curve fitting and dimensionality reductions attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Scipy pdf fitting to do a curve fitting for the petal-length\n",
    "- Plot the normalized histogrm of the petal-length and the estimated pdf on the same figure\n",
    "- Generate new 500 samples using the estimated pdf for the petal-length \n",
    "- Calculate the mean of the new samples and compare how close it is to the mean of the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "- Use Scikit to do PCA on the IRIS dataset\n",
    "- do a bar plot that shows the importance of info in each of the new dimensions\n",
    "- use PCA to reduce the number of attributes by 1. Note that for all the next parts, you will use the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Machine Learning\n",
    "In this part, you will explore the use of supervised and non supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Supervised Learning \n",
    "- using Kmeans, divide the data into different clusters. The number of clusters should be the same as the number of categories you have in the data\n",
    "- Do scatter plot for each two combination of the three dimensions together (0 vs 1), (0 vs 2), (1 vs 2). Use the kmeans labels to color the points in the scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised-Learning\n",
    "- Divide your dataset to 80% training and 20% validation\n",
    "- Build a Logistci regression model for the reduced IRIS dataset\n",
    "- What is the training accuracy\n",
    "- What is the validation accuracy\n",
    "- Form the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve Here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
